{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upper-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instant-technician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.281-b09, mixed mode)\n",
      "  Starting server from C:\\Users\\renat\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\renat\\AppData\\Local\\Temp\\tmpz_tmnje9\n",
      "  JVM stdout: C:\\Users\\renat\\AppData\\Local\\Temp\\tmpz_tmnje9\\h2o_renat_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\renat\\AppData\\Local\\Temp\\tmpz_tmnje9\\h2o_renat_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Sao_Paulo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.0.5</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 day </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_renat_8ht2bp</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.543 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/Sao_Paulo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.0.5\n",
       "H2O_cluster_version_age:    1 day\n",
       "H2O_cluster_name:           H2O_from_python_renat_8ht2bp\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.543 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.9.2 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "christian-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "url = \"http://h2O-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv\"\n",
    "iris = h2o.import_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "going-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = iris.split_frame([0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electrical-trauma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>sepal_len         </th><th>sepal_wid          </th><th>petal_len         </th><th>petal_wid         </th><th>class      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>real              </td><td>real               </td><td>real              </td><td>real              </td><td>enum       </td></tr>\n",
       "<tr><td>mins   </td><td>4.3               </td><td>2.0                </td><td>1.1               </td><td>0.1               </td><td>           </td></tr>\n",
       "<tr><td>mean   </td><td>5.87913043478261  </td><td>3.0373913043478264 </td><td>3.820869565217391 </td><td>1.2156521739130437</td><td>           </td></tr>\n",
       "<tr><td>maxs   </td><td>7.9               </td><td>4.4                </td><td>6.9               </td><td>2.5               </td><td>           </td></tr>\n",
       "<tr><td>sigma  </td><td>0.8313480547283947</td><td>0.44435264752482256</td><td>1.7592111296336783</td><td>0.7493378719755273</td><td>           </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>           </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0          </td></tr>\n",
       "<tr><td>0      </td><td>5.1               </td><td>3.5                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>1      </td><td>4.9               </td><td>3.0                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>2      </td><td>4.7               </td><td>3.2                </td><td>1.3               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>3      </td><td>4.6               </td><td>3.1                </td><td>1.5               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>4      </td><td>5.0               </td><td>3.6                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>5      </td><td>5.4               </td><td>3.9                </td><td>1.7               </td><td>0.4               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>6      </td><td>5.0               </td><td>3.4                </td><td>1.5               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>7      </td><td>4.4               </td><td>2.9                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>8      </td><td>4.9               </td><td>3.1                </td><td>1.5               </td><td>0.1               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>9      </td><td>4.8               </td><td>3.4                </td><td>1.6               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dutch-voltage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acute-client",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recent-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "current-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "mDL = H2ODeepLearningEstimator ()\n",
    "mDL.train([\"sepal_len\",\"sepal_wid\",\"petal_len\",\"petal_wid\"], \"class\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interesting-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1616080931062_1\n",
      "\n",
      "\n",
      "Status of Neuron Layers: predicting class, 3-class classification, multinomial distribution, CrossEntropy loss, 41.803 weights/biases, 498,2 KB, 1.150 training samples, mini-batch size 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_rms</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_rms</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_rms</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>4</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>200</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0030075</td>\n",
       "<td>0.0018919</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0066724</td>\n",
       "<td>0.1065899</td>\n",
       "<td>0.4904452</td>\n",
       "<td>0.0077493</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>200</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0110390</td>\n",
       "<td>0.0378101</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0006194</td>\n",
       "<td>0.0701728</td>\n",
       "<td>0.9987324</td>\n",
       "<td>0.0044337</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>3</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0063332</td>\n",
       "<td>0.0573132</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0188338</td>\n",
       "<td>0.3964483</td>\n",
       "<td>-0.0012392</td>\n",
       "<td>0.0017828</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type       dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  ---------------------\n",
       "    1        4        Input      0.0\n",
       "    2        200      Rectifier  0.0        0.0   0.0   0.0030075343749922465  0.0018919268622994423  0.0         -0.006672364651086013   0.1065899133682251   0.4904451915227356      0.007749326527118683\n",
       "    3        200      Rectifier  0.0        0.0   0.0   0.011039012181793805   0.037810131907463074   0.0         -0.0006193693254035544  0.07017281651496887  0.9987324392809929      0.004433656111359596\n",
       "    4        3        Softmax               0.0   0.0   0.006333213489851914   0.05731320381164551    0.0         -0.01883375495497603    0.3964482545852661   -0.0012392095088199471  0.0017827823758125305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.028292286285126405\n",
      "RMSE: 0.16820311021240483\n",
      "LogLoss: 0.09185570519004774\n",
      "Mean Per-Class Error: 0.024999999999999998\n",
      "AUC: NaN\n",
      "AUCPR: NaN\n",
      "Multinomial auc values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "Multinomial auc_pr values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Iris-setosa</b></td>\n",
       "<td><b>Iris-versicolor</b></td>\n",
       "<td><b>Iris-virginica</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>36.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 36</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>39.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 39</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>37.0</td>\n",
       "<td>0.075</td>\n",
       "<td>3 / 40</td></tr>\n",
       "<tr><td>36.0</td>\n",
       "<td>42.0</td>\n",
       "<td>37.0</td>\n",
       "<td>0.0260870</td>\n",
       "<td>3 / 115</td></tr></table></div>"
      ],
      "text/plain": [
       "Iris-setosa    Iris-versicolor    Iris-virginica    Error     Rate\n",
       "-------------  -----------------  ----------------  --------  -------\n",
       "36             0                  0                 0         0 / 36\n",
       "0              39                 0                 0         0 / 39\n",
       "0              3                  37                0.075     3 / 40\n",
       "36             42                 37                0.026087  3 / 115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.973913</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.973913\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 12:47:18</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 12:47:18</td>\n",
       "<td> 0.286 sec</td>\n",
       "<td>1127 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>115.0</td>\n",
       "<td>0.2885102</td>\n",
       "<td>0.2681581</td>\n",
       "<td>0.8738165</td>\n",
       "<td>0.1217391</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 12:47:19</td>\n",
       "<td> 0.403 sec</td>\n",
       "<td>5348 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>1150.0</td>\n",
       "<td>0.1682031</td>\n",
       "<td>0.0918557</td>\n",
       "<td>0.9571108</td>\n",
       "<td>0.0260870</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error    training_auc    training_pr_auc\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------  --------------  -----------------\n",
       "    2021-03-18 12:47:18  0.000 sec                     0         0             0          nan              nan                 nan            nan                              nan             nan\n",
       "    2021-03-18 12:47:18  0.286 sec   1127 obs/sec      1         1             115        0.28851          0.268158            0.873817       0.121739                         nan             nan\n",
       "    2021-03-18 12:47:19  0.403 sec   5348 obs/sec      10        10            1150       0.168203         0.0918557           0.957111       0.026087                         nan             nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>petal_wid</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2691567</td></tr>\n",
       "<tr><td>petal_len</td>\n",
       "<td>0.9394597</td>\n",
       "<td>0.9394597</td>\n",
       "<td>0.2528619</td></tr>\n",
       "<tr><td>sepal_len</td>\n",
       "<td>0.8974008</td>\n",
       "<td>0.8974008</td>\n",
       "<td>0.2415414</td></tr>\n",
       "<tr><td>sepal_wid</td>\n",
       "<td>0.8784475</td>\n",
       "<td>0.8784475</td>\n",
       "<td>0.2364400</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "petal_wid   1                      1                    0.269157\n",
       "petal_len   0.93946                0.93946              0.252862\n",
       "sepal_len   0.897401               0.897401             0.241541\n",
       "sepal_wid   0.878447               0.878447             0.23644"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "functioning-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "p = mDL.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conditional-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict    </th><th style=\"text-align: right;\">  Iris-setosa</th><th style=\"text-align: right;\">  Iris-versicolor</th><th style=\"text-align: right;\">  Iris-virginica</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      3.77025e-09</td><td style=\"text-align: right;\">     1.49058e-20</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      3.03502e-09</td><td style=\"text-align: right;\">     1.90993e-21</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      9.5711e-09 </td><td style=\"text-align: right;\">     1.60821e-20</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      1.57527e-07</td><td style=\"text-align: right;\">     9.0968e-20 </td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      1.08767e-10</td><td style=\"text-align: right;\">     1.40412e-22</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.999997</td><td style=\"text-align: right;\">      2.73119e-06</td><td style=\"text-align: right;\">     1.96539e-18</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      5.65325e-08</td><td style=\"text-align: right;\">     7.98262e-20</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      2.92355e-07</td><td style=\"text-align: right;\">     3.15562e-19</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      2.07789e-11</td><td style=\"text-align: right;\">     1.97399e-23</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">      6.69355e-08</td><td style=\"text-align: right;\">     2.7527e-20 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adaptive-navigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.024443875380064952\n",
      "RMSE: 0.15634537210952218\n",
      "LogLoss: 0.07570216073519873\n",
      "Mean Per-Class Error: 0.03333333333333333\n",
      "AUC: NaN\n",
      "AUCPR: NaN\n",
      "Multinomial auc values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "Multinomial auc_pr values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Iris-setosa</b></td>\n",
       "<td><b>Iris-versicolor</b></td>\n",
       "<td><b>Iris-virginica</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 14</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 11</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.1</td>\n",
       "<td>1 / 10</td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>12.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>1 / 35</td></tr></table></div>"
      ],
      "text/plain": [
       "Iris-setosa    Iris-versicolor    Iris-virginica    Error      Rate\n",
       "-------------  -----------------  ----------------  ---------  ------\n",
       "14             0                  0                 0          0 / 14\n",
       "0              11                 0                 0          0 / 11\n",
       "0              1                  9                 0.1        1 / 10\n",
       "14             12                 9                 0.0285714  1 / 35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9714286</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.971429\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mDL.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "outer-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "appointed-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "13:36:00.31: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "██████████\n",
      "13:36:07.157: Skipping training of model GBM_5_AutoML_20210318_133600 due to exception: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for GBM model: GBM_5_AutoML_20210318_133600.  Details: ERRR on field: _min_rows: The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 115.0.\n",
      "\n",
      "\n",
      "██████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "mA= H2OAutoML(max_runtime_secs = 30)\n",
    "mA.train([\"sepal_len\",\"sepal_wid\",\"petal_len\",\"petal_wid\"], \"class\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "surprised-cleaners",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "p = mA.leader.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "public-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict    </th><th style=\"text-align: right;\">  Iris-setosa</th><th style=\"text-align: right;\">  Iris-versicolor</th><th style=\"text-align: right;\">  Iris-virginica</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.988366</td><td style=\"text-align: right;\">       0.00419779</td><td style=\"text-align: right;\">      0.00743638</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.988839</td><td style=\"text-align: right;\">       0.00627916</td><td style=\"text-align: right;\">      0.0048818 </td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.98913 </td><td style=\"text-align: right;\">       0.00602476</td><td style=\"text-align: right;\">      0.00484531</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.986393</td><td style=\"text-align: right;\">       0.00843359</td><td style=\"text-align: right;\">      0.00517313</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.989863</td><td style=\"text-align: right;\">       0.00312242</td><td style=\"text-align: right;\">      0.00701505</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.961458</td><td style=\"text-align: right;\">       0.0162508 </td><td style=\"text-align: right;\">      0.0222916 </td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.97422 </td><td style=\"text-align: right;\">       0.0134954 </td><td style=\"text-align: right;\">      0.0122843 </td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.97422 </td><td style=\"text-align: right;\">       0.0134954 </td><td style=\"text-align: right;\">      0.0122843 </td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.989064</td><td style=\"text-align: right;\">       0.00605296</td><td style=\"text-align: right;\">      0.00488292</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.963156</td><td style=\"text-align: right;\">       0.0247867 </td><td style=\"text-align: right;\">      0.0120576 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "prescription-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.05639852946750367\n",
      "RMSE: 0.23748374569116024\n",
      "LogLoss: 0.22356701745742075\n",
      "Mean Per-Class Error: 0.06363636363636364\n",
      "AUC: NaN\n",
      "AUCPR: NaN\n",
      "Multinomial auc values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "Multinomial auc_pr values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Iris-setosa</b></td>\n",
       "<td><b>Iris-versicolor</b></td>\n",
       "<td><b>Iris-virginica</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 14</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>10.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0909091</td>\n",
       "<td>1 / 11</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.1</td>\n",
       "<td>1 / 10</td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>11.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0571429</td>\n",
       "<td>2 / 35</td></tr></table></div>"
      ],
      "text/plain": [
       "Iris-setosa    Iris-versicolor    Iris-virginica    Error      Rate\n",
       "-------------  -----------------  ----------------  ---------  ------\n",
       "14             0                  0                 0          0 / 14\n",
       "0              10                 1                 0.0909091  1 / 11\n",
       "0              1                  9                 0.1        1 / 10\n",
       "14             11                 10                0.0571429  2 / 35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9428572</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.942857\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mA.leader.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "popular-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "motivated-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "mRF = H2ORandomForestEstimator()\n",
    "mRF.train([\"sepal_len\",\"sepal_wid\",\"petal_len\",\"petal_wid\"], \"class\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "studied-xerox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_model_python_1616080931062_2\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>number_of_internal_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>50.0</td>\n",
       "<td>150.0</td>\n",
       "<td>19330.0</td>\n",
       "<td>1.0</td>\n",
       "<td>7.0</td>\n",
       "<td>3.32</td>\n",
       "<td>2.0</td>\n",
       "<td>16.0</td>\n",
       "<td>5.613333</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    50                 150                         19330                  1            7            3.32          2             16            5.61333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.039840594760236124\n",
      "RMSE: 0.19960108907577664\n",
      "LogLoss: 0.1258164148456903\n",
      "Mean Per-Class Error: 0.050427350427350436\n",
      "AUC: NaN\n",
      "AUCPR: NaN\n",
      "Multinomial auc values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "Multinomial auc_pr values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Iris-setosa</b></td>\n",
       "<td><b>Iris-versicolor</b></td>\n",
       "<td><b>Iris-virginica</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>36.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 36</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>37.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0512821</td>\n",
       "<td>2 / 39</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.1</td>\n",
       "<td>4 / 40</td></tr>\n",
       "<tr><td>36.0</td>\n",
       "<td>41.0</td>\n",
       "<td>38.0</td>\n",
       "<td>0.0521739</td>\n",
       "<td>6 / 115</td></tr></table></div>"
      ],
      "text/plain": [
       "Iris-setosa    Iris-versicolor    Iris-virginica    Error      Rate\n",
       "-------------  -----------------  ----------------  ---------  -------\n",
       "36             0                  0                 0          0 / 36\n",
       "0              37                 2                 0.0512821  2 / 39\n",
       "0              4                  36                0.1        4 / 40\n",
       "36             41                 38                0.0521739  6 / 115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9478261</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.947826\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.004 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.011 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.25</td>\n",
       "<td>2.1586735</td>\n",
       "<td>0.03125</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.012 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.2635231</td>\n",
       "<td>2.1758393</td>\n",
       "<td>0.046875</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.014 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2282177</td>\n",
       "<td>1.3654705</td>\n",
       "<td>0.0384615</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.016 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2433190</td>\n",
       "<td>1.5918437</td>\n",
       "<td>0.0449438</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.080 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.2007119</td>\n",
       "<td>0.1267441</td>\n",
       "<td>0.0434783</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.082 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.2008298</td>\n",
       "<td>0.1267909</td>\n",
       "<td>0.0521739</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.083 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.2006362</td>\n",
       "<td>0.1272253</td>\n",
       "<td>0.0521739</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.085 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.2006408</td>\n",
       "<td>0.1270197</td>\n",
       "<td>0.0521739</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2021-03-18 14:23:33</td>\n",
       "<td> 0.086 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1996011</td>\n",
       "<td>0.1258164</td>\n",
       "<td>0.0521739</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse        training_logloss     training_classification_error    training_auc    training_pr_auc\n",
       "---  -------------------  ----------  -----------------  -------------------  -------------------  -------------------------------  --------------  -----------------\n",
       "     2021-03-18 14:23:33  0.004 sec   0.0                nan                  nan                  nan                              nan             nan\n",
       "     2021-03-18 14:23:33  0.011 sec   1.0                0.25                 2.1586735246819178   0.03125                          nan             nan\n",
       "     2021-03-18 14:23:33  0.012 sec   2.0                0.26352313834736496  2.175839341692357    0.046875                         nan             nan\n",
       "     2021-03-18 14:23:33  0.014 sec   3.0                0.22821773229381923  1.36547052490549     0.038461538461538464             nan             nan\n",
       "     2021-03-18 14:23:33  0.016 sec   4.0                0.2433189673046211   1.591843662887205    0.0449438202247191               nan             nan\n",
       "---  ---                  ---         ---                ---                  ---                  ---                              ---             ---\n",
       "     2021-03-18 14:23:33  0.080 sec   46.0               0.2007119184903926   0.12674408227166717  0.043478260869565216             nan             nan\n",
       "     2021-03-18 14:23:33  0.082 sec   47.0               0.2008297550685704   0.1267908896887903   0.05217391304347826              nan             nan\n",
       "     2021-03-18 14:23:33  0.083 sec   48.0               0.20063622436967724  0.12722531978666393  0.05217391304347826              nan             nan\n",
       "     2021-03-18 14:23:33  0.085 sec   49.0               0.20064077616631895  0.12701971908027104  0.05217391304347826              nan             nan\n",
       "     2021-03-18 14:23:33  0.086 sec   50.0               0.19960108907577664  0.1258164148456903   0.05217391304347826              nan             nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>petal_wid</td>\n",
       "<td>1821.0175781</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5436259</td></tr>\n",
       "<tr><td>petal_len</td>\n",
       "<td>1129.8658447</td>\n",
       "<td>0.6204585</td>\n",
       "<td>0.3372973</td></tr>\n",
       "<tr><td>sepal_len</td>\n",
       "<td>314.9659729</td>\n",
       "<td>0.1729615</td>\n",
       "<td>0.0940264</td></tr>\n",
       "<tr><td>sepal_wid</td>\n",
       "<td>83.9128571</td>\n",
       "<td>0.0460802</td>\n",
       "<td>0.0250504</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "petal_wid   1821.02                1                    0.543626\n",
       "petal_len   1129.87                0.620459             0.337297\n",
       "sepal_len   314.966                0.172962             0.0940264\n",
       "sepal_wid   83.9129                0.0460802            0.0250504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "liquid-second",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "p = mRF.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "noted-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.036241402322940056\n",
      "RMSE: 0.1903717477015433\n",
      "LogLoss: 0.10307770077363816\n",
      "Mean Per-Class Error: 0.06363636363636364\n",
      "AUC: NaN\n",
      "AUCPR: NaN\n",
      "Multinomial auc values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "Multinomial auc_pr values: Table is not computed because it is disabled (model parameter 'auc_type' is set to AUTO or NONE) or due to domain size (maximum is 50 domains).\n",
      "\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Iris-setosa</b></td>\n",
       "<td><b>Iris-versicolor</b></td>\n",
       "<td><b>Iris-virginica</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 14</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>10.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0909091</td>\n",
       "<td>1 / 11</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.1</td>\n",
       "<td>1 / 10</td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>11.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0571429</td>\n",
       "<td>2 / 35</td></tr></table></div>"
      ],
      "text/plain": [
       "Iris-setosa    Iris-versicolor    Iris-virginica    Error      Rate\n",
       "-------------  -----------------  ----------------  ---------  ------\n",
       "14             0                  0                 0          0 / 14\n",
       "0              10                 1                 0.0909091  1 / 11\n",
       "0              1                  9                 0.1        1 / 10\n",
       "14             11                 10                0.0571429  2 / 35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9428572</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.942857\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRF.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "recreational-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2ORandomForestEstimator in module h2o.estimators.random_forest:\n",
      "\n",
      "class H2ORandomForestEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  H2ORandomForestEstimator(**kwargs)\n",
      " |  \n",
      " |  Distributed Random Forest\n",
      " |  \n",
      " |  Builds a Distributed Random Forest (DRF) on a parsed dataset, for regression or \n",
      " |  classification.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2ORandomForestEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.base.Keyed\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Construct a new model instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  auc_type\n",
      " |      Set default multinomial AUC type.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"none\"``, ``\"macro_ovr\"``, ``\"weighted_ovr\"``, ``\"macro_ovo\"``, ``\"weighted_ovo\"``\n",
      " |      (default: ``\"auto\"``).\n",
      " |  \n",
      " |  balance_classes\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
      " |      >>> covtype[54] = covtype[54].asfactor()\n",
      " |      >>> predictors = covtype.columns[0:54]\n",
      " |      >>> response = 'C55'\n",
      " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cov_drf = H2ORandomForestEstimator(balance_classes=True,\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> cov_drf.train(x=predictors,\n",
      " |      ...               y=response,\n",
      " |      ...               training_frame=train,\n",
      " |      ...               validation_frame=valid)\n",
      " |      >>> print('logloss', cov_drf.logloss(valid=True))\n",
      " |  \n",
      " |  binomial_double_trees\n",
      " |      For binary classification: Build 2x as many trees (one per class) - can lead to higher accuracy.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(binomial_double_trees=False,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> print('without binomial_double_trees:',\n",
      " |      ...        cars_drf.auc(valid=True))\n",
      " |      >>> cars_drf_2 = H2ORandomForestEstimator(binomial_double_trees=True,\n",
      " |      ...                                       seed=1234)\n",
      " |      >>> cars_drf_2.train(x=predictors,\n",
      " |      ...                  y=response,\n",
      " |      ...                  training_frame=train,\n",
      " |      ...                  validation_frame=valid)\n",
      " |      >>> print('with binomial_double_trees:', cars_drf_2.auc(valid=True))\n",
      " |  \n",
      " |  build_tree_one_node\n",
      " |      Run on one node only; no network overhead but fewer cpus used. Suitable for small datasets.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(build_tree_one_node=True,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> cars_drf.auc(valid=True)\n",
      " |  \n",
      " |  calibrate_model\n",
      " |      Use Platt Scaling to calculate calibrated class probabilities. Calibration can provide more accurate estimates\n",
      " |      of class probabilities.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> ecology = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\n",
      " |      >>> ecology['Angaus'] = ecology['Angaus'].asfactor()\n",
      " |      >>> from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
      " |      >>> response = 'Angaus'\n",
      " |      >>> predictors = ecology.columns[3:13]\n",
      " |      >>> train, calib = ecology.split_frame(seed=12354)\n",
      " |      >>> w = h2o.create_frame(binary_fraction=1,\n",
      " |      ...                      binary_ones_fraction=0.5,\n",
      " |      ...                      missing_fraction=0,\n",
      " |      ...                      rows=744, cols=1)\n",
      " |      >>> w.set_names([\"weight\"])\n",
      " |      >>> train = train.cbind(w)\n",
      " |      >>> ecology_drf = H2ORandomForestEstimator(ntrees=10,\n",
      " |      ...                                        max_depth=5,\n",
      " |      ...                                        min_rows=10,\n",
      " |      ...                                        distribution=\"multinomial\",\n",
      " |      ...                                        weights_column=\"weight\",\n",
      " |      ...                                        calibrate_model=True,\n",
      " |      ...                                        calibration_frame=calib)\n",
      " |      >>> ecology_drf.train(x=predictors,\n",
      " |      ...                   y=\"Angaus\",\n",
      " |      ...                   training_frame=train)\n",
      " |      >>> predicted = ecology_drf.predict(calib)\n",
      " |  \n",
      " |  calibration_frame\n",
      " |      Calibration frame for Platt Scaling\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> ecology = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\n",
      " |      >>> ecology['Angaus'] = ecology['Angaus'].asfactor()\n",
      " |      >>> response = 'Angaus'\n",
      " |      >>> predictors = ecology.columns[3:13]\n",
      " |      >>> train, calib = ecology.split_frame(seed = 12354)\n",
      " |      >>> w = h2o.create_frame(binary_fraction=1,\n",
      " |      ...                      binary_ones_fraction=0.5,\n",
      " |      ...                      missing_fraction=0,\n",
      " |      ...                      rows=744, cols=1)\n",
      " |      >>> w.set_names([\"weight\"])\n",
      " |      >>> train = train.cbind(w)\n",
      " |      >>> ecology_drf = H2ORandomForestEstimator(ntrees=10,\n",
      " |      ...                                        max_depth=5,\n",
      " |      ...                                        min_rows=10,\n",
      " |      ...                                        distribution=\"multinomial\",\n",
      " |      ...                                        calibrate_model=True,\n",
      " |      ...                                        calibration_frame=calib)\n",
      " |      >>> ecology_drf.train(x=predictors,\n",
      " |      ...                   y=\"Angaus,\n",
      " |      ...                   training_frame=train,\n",
      " |      ...                   weights_column=\"weight\")\n",
      " |      >>> predicted = ecology_drf.predict(train)\n",
      " |  \n",
      " |  categorical_encoding\n",
      " |      Encoding scheme for categorical features\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"enum\"``, ``\"one_hot_internal\"``, ``\"one_hot_explicit\"``, ``\"binary\"``, ``\"eigen\"``,\n",
      " |      ``\"label_encoder\"``, ``\"sort_by_response\"``, ``\"enum_limited\"``  (default: ``\"auto\"``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\") \n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> encoding = \"one_hot_explicit\"\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(categorical_encoding=encoding,\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> airlines_drf.auc(valid=True)\n",
      " |  \n",
      " |  check_constant_response\n",
      " |      Check if response column is constant. If enabled, then an exception is thrown if the response column is a\n",
      " |      constant value.If disabled, then model will train regardless of the response column being a constant value or\n",
      " |      not.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris_train.csv\")\n",
      " |      >>> train[\"constantCol\"] = 1\n",
      " |      >>> my_drf = H2ORandomForestEstimator(check_constant_response=False)\n",
      " |      >>> my_drf.train(x=list(range(1,5)),\n",
      " |      ...              y=\"constantCol\",\n",
      " |      ...              training_frame=train)\n",
      " |  \n",
      " |  checkpoint\n",
      " |      Model checkpoint to resume training with.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8],\n",
      " |      ...                                 seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(ntrees=1,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> print(cars_drf.auc(valid=True))\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
      " |      >>> covtype[54] = covtype[54].asfactor()\n",
      " |      >>> predictors = covtype.columns[0:54]\n",
      " |      >>> response = 'C55'\n",
      " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> print(covtype[54].table())\n",
      " |      >>> sample_factors = [1., 0.5, 1., 1., 1., 1., 1.]\n",
      " |      >>> cov_drf = H2ORandomForestEstimator(balance_classes=True,\n",
      " |      ...                                    class_sampling_factors=sample_factors,\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> cov_drf.train(x=predictors,\n",
      " |      ...               y=response,\n",
      " |      ...               training_frame=train,\n",
      " |      ...               validation_frame=valid)\n",
      " |      >>> print('logloss', cov_drf.logloss(valid=True))\n",
      " |  \n",
      " |  col_sample_rate_change_per_level\n",
      " |      Relative change of the column sampling rate for every level (must be > 0.0 and <= 2.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(col_sample_rate_change_per_level=.9,\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>>  print(airlines_drf.auc(valid=True))\n",
      " |  \n",
      " |  col_sample_rate_per_tree\n",
      " |      Column sample rate per tree (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(col_sample_rate_per_tree=.7,\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> print(airlines_drf.auc(valid=True))\n",
      " |  \n",
      " |  custom_metric_func\n",
      " |      Reference to custom evaluation function, format: `language:keyName=funcName`\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  distribution\n",
      " |      [Deprecated] Distribution function\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"bernoulli\"``, ``\"multinomial\"``, ``\"gaussian\"``, ``\"poisson\"``, ``\"gamma\"``,\n",
      " |      ``\"tweedie\"``, ``\"laplace\"``, ``\"quantile\"``, ``\"huber\"``  (default: ``\"auto\"``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"cylinders\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(distribution=\"poisson\",\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> cars_drf.mse(valid=True)\n",
      " |  \n",
      " |  export_checkpoints_dir\n",
      " |      Automatically export generated models to this directory.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> import tempfile\n",
      " |      >>> from os import listdir\n",
      " |      >>> from h2o.grid.grid_search import H2OGridSearch\n",
      " |      >>> airlines = h2o.import_file(\"http://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\", destination_frame=\"air.hex\")\n",
      " |      >>> predictors = [\"DayofMonth\", \"DayOfWeek\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> hyper_parameters = {'ntrees': [5,10]}\n",
      " |      >>> search_crit = {'strategy': \"RandomDiscrete\",\n",
      " |      ...                'max_models': 5,\n",
      " |      ...                'seed': 1234,\n",
      " |      ...                'stopping_rounds': 3,\n",
      " |      ...                'stopping_metric': \"AUTO\",\n",
      " |      ...                'stopping_tolerance': 1e-2}\n",
      " |      >>> checkpoints_dir = tempfile.mkdtemp()\n",
      " |      >>> air_grid = H2OGridSearch(H2ORandomForestEstimator,\n",
      " |      ...                          hyper_params=hyper_parameters,\n",
      " |      ...                          search_criteria=search_crit)\n",
      " |      >>> air_grid.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=airlines,\n",
      " |      ...                distribution=\"bernoulli\",\n",
      " |      ...                max_depth=3,\n",
      " |      ...                export_checkpoints_dir=checkpoints_dir)\n",
      " |      >>> num_files = len(listdir(checkpoints_dir))\n",
      " |      >>> num_files\n",
      " |  \n",
      " |  fold_assignment\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> assignment_type = \"Random\"\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(fold_assignment=assignment_type,\n",
      " |      ...                                     nfolds=5,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=cars)\n",
      " |      >>> cars_drf.auc(xval=True)\n",
      " |  \n",
      " |  fold_column\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> fold_numbers = cars.kfold_column(n_folds=5, seed=1234)\n",
      " |      >>> fold_numbers.set_names([\"fold_numbers\"])\n",
      " |      >>> cars = cars.cbind(fold_numbers)\n",
      " |      >>> print(cars['fold_numbers'])\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=cars,\n",
      " |      ...                fold_column=\"fold_numbers\")\n",
      " |      >>> cars_drf.auc(xval=True)\n",
      " |  \n",
      " |  gainslift_bins\n",
      " |      Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/testng/airlines_train.csv\")\n",
      " |      >>> model = H2ORandomForestEstimator(ntrees=1, gainslift_bins=20)\n",
      " |      >>> model.train(x=[\"Origin\", \"Distance\"],\n",
      " |      ...             y=\"IsDepDelayed\",\n",
      " |      ...             training_frame=airlines)\n",
      " |      >>> model.gains_lift()\n",
      " |  \n",
      " |  histogram_type\n",
      " |      What type of histogram to use for finding optimal split points\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"uniform_adaptive\"``, ``\"random\"``, ``\"quantiles_global\"``, ``\"round_robin\"``  (default:\n",
      " |      ``\"auto\"``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(histogram_type=\"UniformAdaptive\",\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> print(airlines_drf.auc(valid=True))\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |      Ignore constant columns.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> cars[\"const_1\"] = 6\n",
      " |      >>> cars[\"const_2\"] = 7\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(seed=1234,\n",
      " |      ...                                     ignore_const_cols=True)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> cars_drf.auc(valid=True)\n",
      " |  \n",
      " |  ignored_columns\n",
      " |      Names of columns to ignore for training.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(keep_cross_validation_fold_assignment=True,\n",
      " |      ...                                     nfolds=5,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train)\n",
      " |      >>> cars_drf.cross_validation_fold_assignment()\n",
      " |  \n",
      " |  keep_cross_validation_models\n",
      " |      Whether to keep the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(keep_cross_validation_models=True,\n",
      " |      ...                                     nfolds=5,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train)\n",
      " |      >>> cars_drf.auc()\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(keep_cross_validation_predictions=True,\n",
      " |      ...                                     nfolds=5,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train)\n",
      " |      >>> cars_drf.cross_validation_predictions()\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
      " |      >>> covtype[54] = covtype[54].asfactor()\n",
      " |      >>> predictors = covtype.columns[0:54]\n",
      " |      >>> response = 'C55'\n",
      " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> print(covtype[54].table())\n",
      " |      >>> max = .85\n",
      " |      >>> cov_drf = H2ORandomForestEstimator(balance_classes=True,\n",
      " |      ...                                    max_after_balance_size=max,\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> cov_drf.train(x=predictors,\n",
      " |      ...               y=response,\n",
      " |      ...               training_frame=train,\n",
      " |      ...               validation_frame=valid)\n",
      " |      >>> print('logloss', cov_drf.logloss(valid=True))\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_depth\n",
      " |      Maximum tree depth (0 for unlimited).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> df = h2o.import_file(path = \"http://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
      " |      >>> response = \"survived\"\n",
      " |      >>> df[response] = df[response].asfactor()\n",
      " |      >>> predictors = df.columns\n",
      " |      >>> del predictors[1:3]\n",
      " |      >>> train, valid, test = df.split_frame(ratios=[0.6,0.2],\n",
      " |      ...                                     seed=1234,\n",
      " |      ...                                     destination_frames=\n",
      " |      ...                                     ['train.hex','valid.hex','test.hex'])\n",
      " |      >>> drf = H2ORandomForestEstimator()\n",
      " |      >>> drf.train(x=predictors,\n",
      " |      ...           y=response,\n",
      " |      ...           training_frame=train)\n",
      " |      >>> perf = drf.model_performance(valid)\n",
      " |      >>> print perf.auc()\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(max_runtime_secs=10,\n",
      " |      ...                                     ntrees=10000,\n",
      " |      ...                                     max_depth=10,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> cars_drf.auc(valid = True)\n",
      " |  \n",
      " |  min_rows\n",
      " |      Fewest allowed (weighted) observations in a leaf.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(min_rows=16,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> print(cars_drf.auc(valid=True))\n",
      " |  \n",
      " |  min_split_improvement\n",
      " |      Minimum relative improvement in squared error reduction for a split to happen\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1e-05``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(min_split_improvement=1e-3,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> print(cars_drf.auc(valid=True))\n",
      " |  \n",
      " |  mtries\n",
      " |      Number of variables randomly sampled as candidates at each split. If set to -1, defaults to sqrt{p} for\n",
      " |      classification and p/3 for regression (where p is the # of predictors\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
      " |      >>> covtype[54] = covtype[54].asfactor()\n",
      " |      >>> predictors = covtype.columns[0:54]\n",
      " |      >>> response = 'C55'\n",
      " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cov_drf = H2ORandomForestEstimator(mtries=30, seed=1234)\n",
      " |      >>> cov_drf.train(x=predictors,\n",
      " |      ...               y=response,\n",
      " |      ...               training_frame=train,\n",
      " |      ...               validation_frame=valid)\n",
      " |      >>> print('logloss', cov_drf.logloss(valid=True))\n",
      " |  \n",
      " |  nbins\n",
      " |      For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> eeg = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate.csv\")\n",
      " |      >>> eeg['eyeDetection'] = eeg['eyeDetection'].asfactor()\n",
      " |      >>> predictors = eeg.columns[:-1]\n",
      " |      >>> response = 'eyeDetection'\n",
      " |      >>> train, valid = eeg.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> bin_num = [16, 32, 64, 128, 256, 512]\n",
      " |      >>> label = [\"16\", \"32\", \"64\", \"128\", \"256\", \"512\"]\n",
      " |      >>> for key, num in enumerate(bin_num):\n",
      " |      #              Insert integer for 'num' and 'key'\n",
      " |      >>> eeg_drf = H2ORandomForestEstimator(nbins=num, seed=1234)\n",
      " |      >>> eeg_drf.train(x=predictors,\n",
      " |      ...               y=response,\n",
      " |      ...               training_frame=train,\n",
      " |      ...               validation_frame=valid)\n",
      " |      >>> print(label[key], 'training score',\n",
      " |      ...       eeg_drf.auc(train=True))\n",
      " |      >>> print(label[key], 'validation score',\n",
      " |      ...       eeg_drf.auc(train=True))\n",
      " |  \n",
      " |  nbins_cats\n",
      " |      For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher\n",
      " |      values can lead to more overfitting.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1024``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> bin_num = [8, 16, 32, 64, 128, 256,\n",
      " |      ...            512, 1024, 2048, 4096]\n",
      " |      >>> label = [\"8\", \"16\", \"32\", \"64\", \"128\",\n",
      " |      ...          \"256\", \"512\", \"1024\", \"2048\", \"4096\"]\n",
      " |      >>> for key, num in enumerate(bin_num):\n",
      " |      #              Insert integer for 'num' and 'key'\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(nbins_cats=num,\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> print(label[key], 'training score',\n",
      " |      ...       airlines_gbm.auc(train=True))\n",
      " |      >>> print(label[key], 'validation score',\n",
      " |      ...       airlines_gbm.auc(valid=True))\n",
      " |  \n",
      " |  nbins_top_level\n",
      " |      For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then decrease\n",
      " |      by factor of two per level\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1024``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> eeg = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate.csv\")\n",
      " |      >>> eeg['eyeDetection'] = eeg['eyeDetection'].asfactor()\n",
      " |      >>> predictors = eeg.columns[:-1]\n",
      " |      >>> response = 'eyeDetection'\n",
      " |      >>> train, valid = eeg.split_frame(ratios=[.8],\n",
      " |      ...                                seed=1234)\n",
      " |      >>> bin_num = [32, 64, 128, 256, 512,\n",
      " |      ...            1024, 2048, 4096]\n",
      " |      >>> label = [\"32\", \"64\", \"128\", \"256\",\n",
      " |      ...          \"512\", \"1024\", \"2048\", \"4096\"]\n",
      " |      >>> for key, num in enumerate(bin_num):\n",
      " |      #              Insert integer for 'num' and 'key'\n",
      " |      >>> eeg_drf = H2ORandomForestEstimator(nbins_top_level=32,\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> eeg_drf.train(x=predictors,\n",
      " |      ...               y=response,\n",
      " |      ...               training_frame=train,\n",
      " |      ...               validation_frame=valid)\n",
      " |      >>> print(label[key], 'training score',\n",
      " |      ...       eeg_gbm.auc(train=True))\n",
      " |      >>> print(label[key], 'validation score',\n",
      " |      ...       eeg_gbm.auc(valid=True))\n",
      " |  \n",
      " |  nfolds\n",
      " |      Number of folds for K-fold cross-validation (0 to disable or >= 2).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> folds = 5\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(nfolds=folds,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=cars)\n",
      " |      >>> cars_drf.auc(xval=True)\n",
      " |  \n",
      " |  ntrees\n",
      " |      Number of trees.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``50``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
      " |      >>> titanic['survived'] = titanic['survived'].asfactor()\n",
      " |      >>> predictors = titanic.columns\n",
      " |      >>> del predictors[1:3]\n",
      " |      >>> response = 'survived'\n",
      " |      >>> train, valid = titanic.split_frame(ratios=[.8],\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> tree_num = [20, 50, 80, 110,\n",
      " |      ...             140, 170, 200]\n",
      " |      >>> label = [\"20\", \"50\", \"80\", \"110\",\n",
      " |      ...          \"140\", \"170\", \"200\"]\n",
      " |      >>> for key, num in enumerate(tree_num):\n",
      " |      #              Input an integer for 'num' and 'key'\n",
      " |      >>> titanic_drf = H2ORandomForestEstimator(ntrees=num,\n",
      " |      ...                                        seed=1234)\n",
      " |      >>> titanic_drf.train(x=predictors,\n",
      " |      ...                   y=response,\n",
      " |      ...                   training_frame=train,\n",
      " |      ...                   validation_frame=valid)\n",
      " |      >>> print(label[key], 'training score',\n",
      " |      ...       titanic_drf.auc(train=True))\n",
      " |      >>> print(label[key], 'validation score',\n",
      " |      ...       titanic_drf.auc(valid=True))\n",
      " |  \n",
      " |  offset_column\n",
      " |      [Deprecated] Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  r2_stopping\n",
      " |      r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric and\n",
      " |      stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or\n",
      " |      exceeds this\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.797693135e+308``).\n",
      " |  \n",
      " |  response_column\n",
      " |      Response variable column.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  sample_rate\n",
      " |      Row sample rate per tree (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.632``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8],\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(sample_rate=.7,\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> print(airlines_drf.auc(valid=True))\n",
      " |  \n",
      " |  sample_rate_per_class\n",
      " |      A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
      " |      >>> covtype[54] = covtype[54].asfactor()\n",
      " |      >>> predictors = covtype.columns[0:54]\n",
      " |      >>> response = 'C55'\n",
      " |      >>> train, valid = covtype.split_frame(ratios=[.8],\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> print(train[response].table())\n",
      " |      >>> rate_per_class_list = [1, .4, 1, 1, 1, 1, 1]\n",
      " |      >>> cov_drf = H2ORandomForestEstimator(sample_rate_per_class=rate_per_class_list,\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> cov_drf.train(x=predictors,\n",
      " |      ...               y=response,\n",
      " |      ...               training_frame=train,\n",
      " |      ...               validation_frame=valid)\n",
      " |      >>> print('logloss', cov_drf.logloss(valid=True))\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(score_each_iteration=True,\n",
      " |      ...                                     ntrees=55,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame = valid)\n",
      " |      >>> cars_drf.scoring_history()\n",
      " |  \n",
      " |  score_tree_interval\n",
      " |      Score the model after every so many trees. Disabled if set to 0.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(score_tree_interval=5,\n",
      " |      ...                                     seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> cars_drf.scoring_history()\n",
      " |  \n",
      " |  seed\n",
      " |      Seed for pseudo random number generator (if applicable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> drf_w_seed_1 = H2ORandomForestEstimator(seed=1234)\n",
      " |      >>> drf_w_seed_1.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> print('auc for the 1st model build with a seed:',\n",
      " |      ...        drf_w_seed_1.auc(valid=True))\n",
      " |  \n",
      " |  stopping_metric\n",
      " |      Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anonomaly_score\n",
      " |      for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python\n",
      " |      client.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"deviance\"``, ``\"logloss\"``, ``\"mse\"``, ``\"rmse\"``, ``\"mae\"``, ``\"rmsle\"``, ``\"auc\"``,\n",
      " |      ``\"aucpr\"``, ``\"lift_top_group\"``, ``\"misclassification\"``, ``\"mean_per_class_error\"``, ``\"custom\"``,\n",
      " |      ``\"custom_increasing\"``  (default: ``\"auto\"``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8],\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(stopping_metric=\"auc\",\n",
      " |      ...                                         stopping_rounds=3,\n",
      " |      ...                                         stopping_tolerance=1e-2,\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> airlines_drf.auc(valid=True)\n",
      " |  \n",
      " |  stopping_rounds\n",
      " |      Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the\n",
      " |      stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8],\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(stopping_metric=\"auc\",\n",
      " |      ...                                         stopping_rounds=3,\n",
      " |      ...                                         stopping_tolerance=1e-2,\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> airlines_drf.auc(valid=True)\n",
      " |  \n",
      " |  stopping_tolerance\n",
      " |      Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.001``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
      " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
      " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
      " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
      " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
      " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
      " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
      " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
      " |      >>> response = \"IsDepDelayed\"\n",
      " |      >>> train, valid= airlines.split_frame(ratios=[.8],\n",
      " |      ...                                    seed=1234)\n",
      " |      >>> airlines_drf = H2ORandomForestEstimator(stopping_metric=\"auc\",\n",
      " |      ...                                         stopping_rounds=3,\n",
      " |      ...                                         stopping_tolerance=1e-2,\n",
      " |      ...                                         seed=1234)\n",
      " |      >>> airlines_drf.train(x=predictors,\n",
      " |      ...                    y=response,\n",
      " |      ...                    training_frame=train,\n",
      " |      ...                    validation_frame=valid)\n",
      " |      >>> airlines_drf.auc(valid=True)\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8],\n",
      " |      ...                                 seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> cars_drf.auc(valid=True)\n",
      " |  \n",
      " |  validation_frame\n",
      " |      Id of the validation data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8],\n",
      " |      ...                                 seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid)\n",
      " |      >>> cars_drf.auc(valid=True)\n",
      " |  \n",
      " |  weights_column\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the data\n",
      " |      frame. This is typically the number of times a row is repeated, but non-integer values are supported as well.\n",
      " |      During training, rows with higher weights matter more, due to the larger loss function pre-factor.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
      " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
      " |      >>> predictors = [\"displacement\",\"power\",\"acceleration\",\"year\"]\n",
      " |      >>> response = \"economy_20mpg\"\n",
      " |      >>> train, valid = cars.split_frame(ratios=[.8],\n",
      " |      ...                                 seed=1234)\n",
      " |      >>> cars_drf = H2ORandomForestEstimator(seed=1234)\n",
      " |      >>> cars_drf.train(x=predictors,\n",
      " |      ...                y=response,\n",
      " |      ...                training_frame=train,\n",
      " |      ...                validation_frame=valid,\n",
      " |      ...                weights_column=\"weight\")\n",
      " |      >>> cars_drf.auc(valid=True)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = 'drf'\n",
      " |  \n",
      " |  param_names = {'auc_type', 'balance_classes', 'binomial_double_trees',...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  convert_H2OXGBoostParams_2_XGBoostParams(self)\n",
      " |      In order to use convert_H2OXGBoostParams_2_XGBoostParams and convert_H2OFrame_2_DMatrix, you must import\n",
      " |      the following toolboxes: xgboost, pandas, numpy and scipy.sparse.\n",
      " |      \n",
      " |      Given an H2OXGBoost model, this method will generate the corresponding parameters that should be used by\n",
      " |      native XGBoost in order to give exactly the same result, assuming that the same dataset\n",
      " |      (derived from h2oFrame) is used to train the native XGBoost model.\n",
      " |      \n",
      " |      Follow the steps below to compare H2OXGBoost and native XGBoost:\n",
      " |      \n",
      " |       1. Train the H2OXGBoost model with H2OFrame trainFile and generate a prediction:\n",
      " |      \n",
      " |        - h2oModelD = H2OXGBoostEstimator(\\*\\*h2oParamsD) # parameters specified as a dict()\n",
      " |        - h2oModelD.train(x=myX, y=y, training_frame=trainFile) # train with H2OFrame trainFile\n",
      " |        - h2oPredict = h2oPredictD = h2oModelD.predict(trainFile)\n",
      " |      \n",
      " |       2. Derive the DMatrix from H2OFrame:\n",
      " |       \n",
      " |        - nativeDMatrix = trainFile.convert_H2OFrame_2_DMatrix(myX, y, h2oModelD)\n",
      " |      \n",
      " |       3. Derive the parameters for native XGBoost:\n",
      " |       \n",
      " |        - nativeParams = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()\n",
      " |      \n",
      " |       4. Train your native XGBoost model and generate a prediction:\n",
      " |       \n",
      " |        - nativeModel = xgb.train(params=nativeParams[0], dtrain=nativeDMatrix, num_boost_round=nativeParams[1])\n",
      " |        - nativePredict = nativeModel.predict(data=nativeDMatrix, ntree_limit=nativeParams[1]\n",
      " |      \n",
      " |       5. Compare the predictions h2oPredict from H2OXGBoost, nativePredict from native XGBoost.\n",
      " |      \n",
      " |      :return: nativeParams, num_boost_round\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      :param bool verbose: Print scoring history to stdout. Defaults to False.\n",
      " |  \n",
      " |  train_segments(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, segments=None, segment_models_id=None, parallelism=1, verbose=False)\n",
      " |      Trains H2O model for each segment (subpopulation) of the training dataset.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for each model training. Use 0 to disable.\n",
      " |          Please note that regardless of how this parameter is set, a model will be built for each input segment.\n",
      " |          This parameter only affects individual model training.\n",
      " |      :param segments: A list of columns to segment-by. H2O will group the training (and validation) dataset\n",
      " |          by the segment-by columns and train a separate model for each segment (group of rows).\n",
      " |          As an alternative to providing a list of columns, users can also supply an explicit enumeration of\n",
      " |          segments to build the models for. This enumeration needs to be represented as H2OFrame.\n",
      " |      :param segment_models_id: Identifier for the returned collection of Segment Models. If not specified\n",
      " |          it will be automatically generated.\n",
      " |      :param parallelism: Level of parallelism of the bulk segment models building, it is the maximum number \n",
      " |          of models each H2O node will be building in parallel.\n",
      " |      :param bool verbose: Enable to print additional information during model building. Defaults to False.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> response = \"survived\"\n",
      " |      >>> titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
      " |      >>> titanic[response] = titanic[response].asfactor()\n",
      " |      >>> predictors = [\"survived\",\"name\",\"sex\",\"age\",\"sibsp\",\"parch\",\"ticket\",\"fare\",\"cabin\"]\n",
      " |      >>> train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
      " |      >>> from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
      " |      >>> titanic_gbm = H2OGradientBoostingEstimator(seed=1234)\n",
      " |      >>> titanic_models = titanic_gbm.train_segments(segments=[\"pclass\"],\n",
      " |      ...                                             x=predictors,\n",
      " |      ...                                             y=response,\n",
      " |      ...                                             training_frame=train,\n",
      " |      ...                                             validation_frame=valid)\n",
      " |      >>> titanic_models.as_frame()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  aucpr(self, train=False, valid=False, xval=False)\n",
      " |      Get the aucPR (Area Under PRECISION RECALL Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the aucpr value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the aucpr value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the aucpr value for the validation data.\n",
      " |      \n",
      " |      :returns: The aucpr.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  detach(self)\n",
      " |      Detach the Python object from the backend, usually by clearing its key\n",
      " |  \n",
      " |  download_model(self, path='')\n",
      " |      Download an H2O Model object to disk.\n",
      " |      \n",
      " |      :param model: The model object to download.\n",
      " |      :param path: a path to the directory where the model should be saved.\n",
      " |      \n",
      " |      :returns: the path of the downloaded model\n",
      " |  \n",
      " |  download_mojo(self, path='.', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name: Custom name of genmodel jar\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path='', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name: Custom name of genmodel jar\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  feature_frequencies(self, test_data)\n",
      " |      Retrieve the number of occurrences of each feature for given observations \n",
      " |      on their respective paths in a tree ensemble model.\n",
      " |      Available for GBM, Random Forest and Isolation Forest models.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to calculate feature frequencies.\n",
      " |      \n",
      " |      :returns: A new H2OFrame made of feature contributions.\n",
      " |  \n",
      " |  feature_interaction(self, max_interaction_depth=100, max_tree_depth=100, max_deepening=-1, path=None)\n",
      " |      Feature interactions and importance, leaf statistics and split value histograms in a tabular form.\n",
      " |      Available for XGBoost and GBM.\n",
      " |      \n",
      " |      Metrics:\n",
      " |      Gain - Total gain of each feature or feature interaction.\n",
      " |      FScore - Amount of possible splits taken on a feature or feature interaction.\n",
      " |      wFScore - Amount of possible splits taken on a feature or feature interaction weighed by \n",
      " |      the probability of the splits to take place.\n",
      " |      Average wFScore - wFScore divided by FScore.\n",
      " |      Average Gain - Gain divided by FScore.\n",
      " |      Expected Gain - Total gain of each feature or feature interaction weighed by the probability to gather the gain.\n",
      " |      Average Tree Index\n",
      " |      Average Tree Depth\n",
      " |      \n",
      " |      :param max_interaction_depth: Upper bound for extracted feature interactions depth. Defaults to 100.\n",
      " |      :param max_tree_depth: Upper bound for tree depth. Defaults to 100.\n",
      " |      :param max_deepening: Upper bound for interaction start deepening (zero deepening => interactions \n",
      " |      starting at root only). Defaults to -1.\n",
      " |      :param path: Path where to save the output in .xlsx format. Please note that Pandas and XlsxWriter need to be \n",
      " |      installed for using this option. Defaults to None.\n",
      " |      \n",
      " |      :examples:\n",
      " |      >>> boston = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/BostonHousing.csv\")\n",
      " |      >>> predictors = boston.columns[:-1]\n",
      " |      >>> response = \"medv\"\n",
      " |      >>> boston['chas'] = boston['chas'].asfactor()\n",
      " |      >>> train, valid = boston.split_frame(ratios=[.8])\n",
      " |      >>> boston_xgb = H2OXGBoostEstimator(seed=1234)\n",
      " |      >>> boston_xgb.train(y=response, x=predictors, training_frame=train)\n",
      " |      >>> feature_interactions = boston_xgb.feature_interaction()\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  ntrees_actual(self)\n",
      " |      Returns actual number of trees in a tree model. If early stopping enabled, GBM can reset the ntrees value.\n",
      " |      In this case, the actual ntrees value is less than the original ntrees value a user set before\n",
      " |      building the model.\n",
      " |      \n",
      " |      Type: ``float``\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols=None, destination_key=None, nbins=20, weight_column=None, plot=True, plot_stddev=True, figsize=(7, 10), server=False, include_na=False, user_splits=None, col_pairs_2dpdp=None, save_to_file=None, row_index=None, targets=None)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count. If you enable add_missing_NA, the returned length will be nbin+1.\n",
      " |      :param weight_column: A string denoting which column of data should be used as the weight column.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: Specify whether to activate matplotlib \"server\" mode. In this case, the plots are saved to a file instead of being rendered.\n",
      " |      :param include_na: A boolean specifying whether missing value should be included in the Feature values.\n",
      " |      :param user_splits: a dictionary containing column names as key and user defined split values as value in a list.\n",
      " |      :param col_pairs_2dpdp: list containing pairs of column names for 2D pdp\n",
      " |      :param save_to_file: Fully qualified name to an image file the resulting plot should be saved to, e.g. '/home/user/pdpplot.png'. The 'png' postfix might be omitted. If the file already exists, it will be overridden. Plot is only saved if plot = True.\n",
      " |      :param row_index: Row for which partial dependence will be calculated instead of the whole input frame.\n",
      " |      :param targets: Target classes for multiclass model.\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  pr_auc(self, train=False, valid=False, xval=False)\n",
      " |      ``ModelBase.pr_auc`` is deprecated, please use ``ModelBase.aucpr`` instead.\n",
      " |  \n",
      " |  predict(self, test_data, custom_metric=None, custom_metric_func=None)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param custom_metric:  custom evaluation function defined as class reference, the class get uploaded\n",
      " |          into the cluster\n",
      " |      :param custom_metric_func: custom evaluation function reference, e.g, result of upload_custom_metric\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_contributions(self, test_data)\n",
      " |      Predict feature contributions - SHAP values on an H2O Model (only DRF, GBM and XGBoost models).\n",
      " |      \n",
      " |      Returned H2OFrame has shape (#rows, #features + 1) - there is a feature contribution column for each input\n",
      " |      feature, the last column is the model bias (same value for each row). The sum of the feature contributions\n",
      " |      and the bias term is equal to the raw prediction of the model. Raw prediction of tree-based model is the sum \n",
      " |      of the predictions of the individual trees before before the inverse link function is applied to get the actual\n",
      " |      prediction. For Gaussian distribution the sum of the contributions is equal to the model prediction. \n",
      " |      \n",
      " |      Note: Multinomial classification models are currently not supported.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to calculate contributions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame made of feature contributions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data, type='Path')\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param Enum type: How to identify the leaf node. Nodes can be either identified by a path from to the root node\n",
      " |          of the tree to the node or by H2O's internal node id. One of: ``\"Path\"``, ``\"Node_ID\"`` (default: ``\"Path\"``).\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path='', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path='', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  staged_predict_proba(self, test_data)\n",
      " |      Predict class probabilities at each stage of an H2O Model (only GBM models).\n",
      " |      \n",
      " |      The output structure is analogous to the output of function predict_leaf_node_assignment. For each tree t and\n",
      " |      class c there will be a column Tt.Cc (eg. T3.C1 for tree 3 and class 1). The value will be the corresponding\n",
      " |      predicted probability of this class by combining the raw contributions of trees T1.Cc,..,TtCc. Binomial models\n",
      " |      build the trees just for the first class and values in columns Tx.C1 thus correspond to the the probability p0.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of staged predictions.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: if true set server settings to matplotlib and show the graph\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  training_model_metrics(self)\n",
      " |      Return training model metrics for any model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param bool use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
      " |      :param server: if true set server settings to matplotlib and show the graph\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  end_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was ended.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  have_mojo\n",
      " |      True, if export to MOJO is possible\n",
      " |  \n",
      " |  have_pojo\n",
      " |      True, if export to POJO is possible\n",
      " |  \n",
      " |  key\n",
      " |      :return: the unique key representing the object on the backend\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  run_time\n",
      " |      Model training time in milliseconds\n",
      " |  \n",
      " |  start_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was started.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.base.Keyed:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(h2o.estimators.random_forest.H2ORandomForestEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "alternative-broadcast",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7da773c9e27b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh2o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-dealing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
